# yt Team Meeting 2017-04-19

Notes by: Matt Turk

Attendees:

 * Alex Lindsay
 * Ben Keller
 * Bili Dong
 * Britton Smith
 * Cameron Hummels
 * John ZuHone
 * Kacper Kowalik
 * Nathan Goldbaum
 * Matthew Turk

(In order from left to right in the hangout window on my desktop.)

## Agenda

 * Should we put meeting agenda/notes into a repo?
 * Where are we at? (Open, but guided, discussion)
   * Community
   * Support for codes
   * Utilization
   * "Buzz"
 * yt development workshop
 * Update on hg/git conversion
   * Requests for help
   * Timeline and open questions
 * Updates on projects
   * Demeshening
   * Splitting out analysis modules
 * yt 4.0?

## Notes

Decided to keep meeting notes in a repository.  This is the first one!

## Where are we at?

**Community**

How is the yt community doing?  Nathan points out that in the last five months
or so we've added about 8 contributors, which is good.  Some discussion about
folks not coming along and participating that much, which is something we are
hoping for with moving to GitHub.

Some questions about how contribution docs are, and the idea was that they're
reasonably good.  We'll have to update them for next.  One primary barrier
identified was learning mercurial.  ("Didn't mind, but it was a barrier.")

Can get very timely help when I want to contribute to something, which is very
helpful.  Very quick response for questions.  Biggest barrier: for the project
wants to work on, doesn't have good knowledge of how the code is working.  Docs
are very good for users, but for developers to understand the inner works, the
code is the primary source of information.

Developer documentation is lacking; how do we keep those up to date?  yt method
paper was described as being in development.  One particular note was the
chunking system, which was not kept up to date in the docs, but is present in
YTEPs.

Quotation: Sounds like things are maybe doing alright.  And maybe GitHub will
help out a lot with that.

Comment: come back and revisit once we migrate.

Maybe the code is just mature in some places?

Suggestion that we should absolutely rely on the GitHub provided documentation
for how to contribute things to yt on GitHub.  This might lead to an overall
reduction in contributor guidelines.

**Support for Codes**

Where are we weak?

Something that comes up every so often is RAMSES.  Our support for Octree data
isn't as good as for other data.  This affects SPH, but it also affects Octree.
For instance, ghost zones, volume rendering, etc.

Our ability for SPH data to be nice (and not slow, ram consuming, etc) will be
improved once demeshening goes in.

**Utilization**

We get a reasonable number of new people asking questions.

At INL, Alex was surprised by the number of people who said they'd tried using
yt.  Lot of general interest after showing second order mesh support.  General
interest in wrapping it into the MOOSE GUI.

Lot of potential expanded utilization in MOOSE.  Ben suggests the ADS page
suggests we've gotten a lot of use.  30 in 2017 so far.  Could be historical
users publishing more.  Seems like a good sign though.

**Buzz**

Nathan and John were interviewed by
[Podcast.__init__](https://www.podcastinit.com/) and will post the episode when
it airs.

## yt development workshop

Proposal: September, Champaign.

Todo: Matt will send out "which weeks in September and early October work."

## Migration from Bitbucket to GitHub

We have:

 * Working mirror bot
 * Final repo staged at https://github.com/yt-project/yt
 * Going to be developing on `master` rather than to `yt`.
 * Continuing with `stable` and current merge pattern.

At present, syncing works completely; can use the same script in reverse to
sync *back* to bitbucket.  This will let people continue to use `hg` to sync
with upstream.  Will have to export work in progress to git.

Have to update `yt update` to grab from git using gitpython or something.
Website repo assumes hg, so we'll need to update that tooling.

Alex volunteered to help write documentation for git use.  Mostly,
documentation that references hg should be updated.

Pushing to github from hg is super easy; biggest issue is the branches, which
will need to be bookmarks.

First push will be slow.  Suggested that we just let stuff happen on 
branch `default` and fix `yt update` to update to that.

Lots of discussion of branches and bookmarks...

We will be pushing people to switch to the GitHub repository and not rely on
the BitBucket one.

Timeline: support for the timeline in
[YTEP-1000](https://bitbucket.org/yt_analysis/ytep/pull-requests/68/adding-draft-github-migration-ytep/diff)
where we start migration May 1, end on May 15.

## Update on Projects

**Demeshening**

Nathan has been working to integrate into yt the bitmap
indexing that Meagan Lang worked on.  Nathan has been doing all of the
high-level API changes to make this natural.

What works:

 * IO for all supported codes, including stream, Gadget, Tipsy, etc.
 * Generates smoothing lengths using a kD-tree for nearest neighbors.
   Generalizable, and the kD-tree lib will be either dependencied or vendored.
   Can do nearest neighbors for fields, etc.
 * All data objects work and are tested
 * Making images work; projections, even.  Memory usage is *way* down.

Will need to do:

 * Octree data object onto which data can be deposited
 * A few decisions about projections.

"Might still not be *completely* done at end of summer, but it'll be close to
being there."

Nathan explained the EWAH system and indexing scheme.

**Splitting Out Analysis Modules**

Britton has something to say about this, he informs us.

There is an accepted [pull request to
trident](https://bitbucket.org/trident-project/trident/pull-requests/20/pulling-trident-related-yt-classes-into/commits)
that pulls out the yt classes into trident, but they have not been removed from
yt.

Britton wants to do a few more.  To do so, he's probably going to use either hg
or git, depending on the timescale.  This will pull out the ones from the
[spreadsheet](https://docs.google.com/spreadsheets/d/1uMGD5fjV7eHjNGWek1uGA-GP-xrfmWRMMN54Tkb2Gnc/edit?usp=sharing) he created a while back.

Next two he wants to do: halo analysis and halo finding, smashed together.
Cosmological observation as well.  Also maybe the attic.  This list keeps
getting longer, and I am not going to edit this paragraph to make it into a
bullet point list.

**Grid Visitors**

Running into issues with GAMER datasets and grid sizes.  Grid visitors is a
project ready to go to help with this, especially by reducing the memory
overhead.  With some GAMER datasets, we run into scaling issues because of the
memory overhead of the grid objects themselves.

**Other Updates**

Trident is doing well!  Demeshening will help it.  John comments that the
demeshening will help with particle field analysis.

## yt 3.4 and yt 4.0

Releases!  How do we do them?  Britton would like to start talking about 3.4
because it will address a number of issues, especially how we "do" releases.

Now that we're on GitHub, does our release process change?  Nathan proposes
that we wait until we're fully on GitHub to do a 3.4.  Issue tracker will be
particularly helpful because we can triage more easily and label things.

Nathan suggests that we do a full issue triage for each release.  He doesn't
think we're in a situation like we were last summer, with a big broken
incomplete feature that needs a sprint.

Britton thinks we should limit ourselves to regressions and limited big deals
for what we use as blockers.  He thinks we have overburdened ourselves with too
many issues, and if we make too many blockers, we never get anywhere.  Nathan
agrees.

What is ideal for number of big releases each year?  Right now we're at one per
year.  Would be nice to speed up to every six months.  Otherwise, people end up
waiting too long.

Absolute latest for 3.4 is likely going to be the SciPy conference.

A couple things have been proposed for a 4.0, because they'd break things.
Demeshening and non-spatial coordinate systems are the two big ones.
This includes different indexing schemes as well as `YTIndexArray` objects;
John is almost completely done with that, but a few things remaining.  Want to
make sure that we support things in curvilinear coordinates correctly.  Getting
the API and UI correct there is a big deal.

Suggestion is made to deprecate analysis modules in 3.4, remove them by 4.0.

Goal with 4.0: if you're using yt with patch AMR, your user experience should
be the same.  If you're using it with SPH, things will change, but in a
minimally invasive way.

Could also do cleanups, etc, but want to be much less disruptive than 3.0.

## Python 2 deprecation

John brings up the question of when we should deprecate Python 2 and move to 3.
There's a [website](http://www.python3statement.org/) about this.  CPython will
support until 2020, and after that date, completely unsupported.

Lots of other projects are in process of dropping support.  For instance,
IPython, the current stable release only runs on 3.  IPython 5 (LTS) will run
on Python 2, but IPython 6 will only do 3.

If we agree to drop Python 2 support for a future release, that will enable
some really nice things.  For instance, we could clean up a ton of things if we
dropped Python 2 in yt 4.0; this could include `future` imports.  Making it run
on both is a barrier to entry.  There's an accumulation of nice things in
Python 3 now.

Nathan had proposed 4.0, Matt supported this.  Britton suggested 4.1.  If we go
to a six month release cycle, that would put us at Summer 2018.

[Much discussion!  Especially around long term support (LTS) releases.]

Proposal: when 3.4 comes out, start conversation.  When 4.0 comes out, say it
will be last one to support Python 2.  That's more than a year from now.  "At
end of day, only thing we can do is give warning."  This won't be decided on
the call, but this is the start of the conversation.  We will kick the can a
bit further down the road, but revisit in time for 3.4, and sign on to the
Python3 statement.

**THE END**
